<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.1.0 for Hugo"><meta name=author content="Yi Rong"><meta name=description content="The last decade has witnessed growth in the computational requirements for training deep neural networks. Current approaches (e.g., data/model parallelism, pipeline parallelism) parallelize training tasks onto multiple devices. However, these approaches always rely on specific deep learning frameworks and requires elaborate manual design, which make it difficult to maintain and share between different type of models. In this paper, we propose Auto-MAP, a framework for exploring distributed execution plans for DNN workloads, which can automatically discovering fast parallelization strategies through reinforcement learning on IR level of deep learning models. Efficient exploration remains a major challenge for reinforcement learning. We leverage DQN with task-specific pruning strategies to help efficiently explore the search space including optimized strategies. Our evaluation shows that Auto-MAP can find the optimal solution in two hours, while achieving better throughput on several NLP and convolution models."><link rel=alternate hreflang=zh href=https://rongyi.ai/zh/publication/automap/><link rel=alternate hreflang=en-us href=https://rongyi.ai/publication/automap/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#007bff"><script src=/js/mathjax-config.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CLato:400,700%7CMerriweather%7CRoboto+Mono&display=swap"><link rel=stylesheet href=/css/wowchemy.5400eb523618abd9a2179150357d5e24.css><script async src="https://www.googletagmanager.com/gtag/js?id=UA-140806673-3"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(a,b){gtag('event','click',{event_category:'outbound',event_label:a,transport_type:'beacon',event_callback:function(){b!=='_blank'&&(document.location=a)}}),console.debug("Outbound link clicked: "+a)}function onClickCallback(a){if(a.target.tagName!=='A'||a.target.host===window.location.host)return;trackOutboundLink(a.target,a.target.getAttribute('target'))}gtag('js',new Date),gtag('config','UA-140806673-3',{}),gtag('set',{cookie_flags:'SameSite=None;Secure'}),document.addEventListener('click',onClickCallback,!1)</script><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hucf03f274847a1149dd55649cb0f12563_327173_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/media/icon_hucf03f274847a1149dd55649cb0f12563_327173_180x180_fill_lanczos_center_2.png><link rel=canonical href=https://rongyi.ai/publication/automap/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@LER0ever"><meta property="twitter:creator" content="@LER0ever"><meta property="og:site_name" content="L.E.R Academic"><meta property="og:url" content="https://rongyi.ai/publication/automap/"><meta property="og:title" content="Auto-MAP: A DQN Framework for Exploring Distributed Execution Plans for DNN Workloads | L.E.R Academic"><meta property="og:description" content="The last decade has witnessed growth in the computational requirements for training deep neural networks. Current approaches (e.g., data/model parallelism, pipeline parallelism) parallelize training tasks onto multiple devices. However, these approaches always rely on specific deep learning frameworks and requires elaborate manual design, which make it difficult to maintain and share between different type of models. In this paper, we propose Auto-MAP, a framework for exploring distributed execution plans for DNN workloads, which can automatically discovering fast parallelization strategies through reinforcement learning on IR level of deep learning models. Efficient exploration remains a major challenge for reinforcement learning. We leverage DQN with task-specific pruning strategies to help efficiently explore the search space including optimized strategies. Our evaluation shows that Auto-MAP can find the optimal solution in two hours, while achieving better throughput on several NLP and convolution models."><meta property="og:image" content="https://rongyi.ai/media/icon_hucf03f274847a1149dd55649cb0f12563_327173_512x512_fill_lanczos_center_2.png"><meta property="twitter:image" content="https://rongyi.ai/media/icon_hucf03f274847a1149dd55649cb0f12563_327173_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2020-08-04T15:52:59+08:00"><meta property="article:modified_time" content="2021-07-03T00:35:26+08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://rongyi.ai/publication/automap/"},"headline":"Auto-MAP: A DQN Framework for Exploring Distributed Execution Plans for DNN Workloads","datePublished":"2020-08-04T15:52:59+08:00","dateModified":"2021-07-03T00:35:26+08:00","author":{"@type":"Person","name":"Siyu Wang"},"publisher":{"@type":"Organization","name":"L.E.R Academic","logo":{"@type":"ImageObject","url":"https://rongyi.ai/media/icon_hucf03f274847a1149dd55649cb0f12563_327173_192x192_fill_lanczos_center_2.png"}},"description":"The last decade has witnessed growth in the computational requirements for training deep neural networks. Current approaches (e.g., data/model parallelism, pipeline parallelism) parallelize training tasks onto multiple devices. However, these approaches always rely on specific deep learning frameworks and requires elaborate manual design, which make it difficult to maintain and share between different type of models. In this paper, we propose Auto-MAP, a framework for exploring distributed execution plans for DNN workloads, which can automatically discovering fast parallelization strategies through reinforcement learning on IR level of deep learning models. Efficient exploration remains a major challenge for reinforcement learning. We leverage DQN with task-specific pruning strategies to help efficiently explore the search space including optimized strategies. Our evaluation shows that Auto-MAP can find the optimal solution in two hours, while achieving better throughput on several NLP and convolution models."}</script><title>Auto-MAP: A DQN Framework for Exploring Distributed Execution Plans for DNN Workloads | L.E.R Academic</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=1f9f6672cbf7545321841735f466ae97><script src=/js/wowchemy-init.min.226a9011996d125bf3fe4a5f22353a49.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>L.E.R Academic</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>L.E.R Academic</a></div><div class="navbar-collapse main-menu-item collapse justify-content-center" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>About</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=https://rongyi.io target=_blank rel=noopener><span>Home</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li><li class="nav-item dropdown i18n-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label=Languages><i class="fas fa-globe mr-1" aria-hidden=true></i></a><div class=dropdown-menu><div class="dropdown-item dropdown-item-active"><span>English</span></div><a class=dropdown-item href=https://rongyi.ai/zh/publication/automap/><span>中文 (简体)</span></a></div></li></ul></div></nav></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Auto-MAP: A DQN Framework for Exploring Distributed Execution Plans for DNN Workloads</h1><div class=article-metadata><div><span><a href=/author/siyu-wang/>Siyu Wang</a></span>, <span><a href=/author/yi-rong/>Yi Rong</a></span>, <span><a href=/author/shiqing-fan/>Shiqing Fan</a></span>, <span><a href=/author/zhen-zheng/>Zhen Zheng</a></span>, <span><a href=/author/lansong-diao/>LanSong Diao</a></span>, <span><a href=/author/guoping-long/>Guoping Long</a></span>, <span><a href=/author/jun-yang/>Jun Yang</a></span>, <span><a href=/author/xiaoyong-liu/>Xiaoyong Liu</a></span>, <span><a href=/author/wei-lin/>Wei Lin</a></span></div><span class=article-date>July 2020</span>
<span class=middot-divider></span><span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/distributed-training/>Distributed Training</a>, <a href=/category/reinforcement-learning/>Reinforcement Learning</a></span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=/pdf/automap-arxiv.html target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/2007.04069 target=_blank rel=noopener>Source Document</a></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>The last decade has witnessed growth in the computational requirements for training deep neural networks. Current approaches (e.g., data/model parallelism, pipeline parallelism) parallelize training tasks onto multiple devices. However, these approaches always rely on specific deep learning frameworks and requires elaborate manual design, which make it difficult to maintain and share between different type of models. In this paper, we propose Auto-MAP, a framework for exploring distributed execution plans for DNN workloads, which can automatically discovering fast parallelization strategies through reinforcement learning on IR level of deep learning models. Efficient exploration remains a major challenge for reinforcement learning. We leverage DQN with task-specific pruning strategies to help efficiently explore the search space including optimized strategies. Our evaluation shows that Auto-MAP can find the optimal solution in two hours, while achieving better throughput on several NLP and convolution models.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#3>Preprint</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">arXiv.org e-Print archive</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/dqn/>DQN</a>
<a class="badge badge-light" href=/tag/data-parallelism/>Data Parallelism</a>
<a class="badge badge-light" href=/tag/sharding/>Sharding</a>
<a class="badge badge-light" href=/tag/pipeline-parallelism/>Pipeline Parallelism</a>
<a class="badge badge-light" href=/tag/deep-reinforcement-learning/>Deep Reinforcement Learning</a></div><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://rongyi.ai/publication/automap/&text=Auto-MAP:%20A%20DQN%20Framework%20for%20Exploring%20Distributed%20Execution%20Plans%20for%20DNN%20Workloads" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://rongyi.ai/publication/automap/&t=Auto-MAP:%20A%20DQN%20Framework%20for%20Exploring%20Distributed%20Execution%20Plans%20for%20DNN%20Workloads" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Auto-MAP:%20A%20DQN%20Framework%20for%20Exploring%20Distributed%20Execution%20Plans%20for%20DNN%20Workloads&body=https://rongyi.ai/publication/automap/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://rongyi.ai/publication/automap/&title=Auto-MAP:%20A%20DQN%20Framework%20for%20Exploring%20Distributed%20Execution%20Plans%20for%20DNN%20Workloads" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Auto-MAP:%20A%20DQN%20Framework%20for%20Exploring%20Distributed%20Execution%20Plans%20for%20DNN%20Workloads%20https://rongyi.ai/publication/automap/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://rongyi.ai/publication/automap/&title=Auto-MAP:%20A%20DQN%20Framework%20for%20Exploring%20Distributed%20Execution%20Plans%20for%20DNN%20Workloads" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://rongyi.ai><img class="avatar mr-3 avatar-circle" src=/author/yi-rong/avatar_hu2ea8f54534c8b0cd62574e44d83aec0c_3111663_270x270_fill_lanczos_center_2.png alt="Yi Rong"></a><div class=media-body><h5 class=card-title><a href=https://rongyi.ai>Yi Rong</a></h5><h6 class=card-subtitle>Research Intern</h6><p class=card-text>My research interests include Machine Learning, Compilers and PL Design</p><ul class=network-icon aria-hidden=true><li><a href=mailto:hi@rongyi.ai><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/LER0ever target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.com/citations?user=PH8z_3gAAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/LER0ever target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>© 2021 Yi Rong &nbsp;&#183;&nbsp;
<a href=https://rongyi.io target=_blank>Home: rongyi.io</a>
&nbsp;&#183;&nbsp;
<a href=https://status.rongyi.io target=_blank>System Status</a></p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/en/js/wowchemy.min.b61a8f62b6e5c0cd322c8158c5b5dfb6.js></script></body></html>